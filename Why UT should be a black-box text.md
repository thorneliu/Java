# 单元测试：测代码实现还是测其功能？

## 概述
单元测试（UT）代码是整个特性交付中必不可少的一部分。在我们日常的工程开发实践中，我们会做很多关于如何实现产品功能性代码的讨论；与此形成对比的是，我们的单元测试代码大多数却被认定为产品的代码一个“补充”，因而程序员们对于为何实现需要交付单元测试以及如何交付优秀的单元测试认识不足。


在工作中，通常我们的单元测试代码通常以现有代码实现为蓝本，通过单元测试的框架来逐一覆盖功能代码中的流程及分支。一个认真细致的程序员基于这样的策略能够输出覆盖率为100%的单元测试。由于这样单元测试是基于已有的代码实现来完成的，校验的是被测类的具体**代码实现**，是一种在已知被测对象实现细节情况下的**白盒测试**。

与白盒测试相对应概念的是**黑盒测试**。黑盒测试策略下输出的单元测试代码不关注被测对象的具体实现。 在这样的情况下，我们把被测类看成一个统一的整体，对外提供约定好的功能及服务。因此这类单元测试代码将重点关注被测类的行为是否符合预期。至于被测类是通过什么样的代码流程来实现这样的功能，提供某项服务，单元测试代码将不做验证。这就是校验被测类**功能/行为**的单元测试用例。

对比两种不同策略的单元测试，我们更需要哪一种呢？答案是我们需要更多关注代码功能的单元测试用例，我们应该在工作中输出更多把被测类作为黑盒的UT代码。接下来的章节讲详细解释两类单元测试代码的优劣。

## 白盒测试

在我们的工作流程中，实现UT代码第一个功利性的需求来源于提交一部分产品代码时需要满足CI系统对于UT覆盖率的硬性需求。基于此种需求输出UT代码的流程基本是这样的：

1. 完成本次提交需要的功能性代码
2. 对所有的产品代码补单元测试
3. 调试单元测试用例，并满足CI关于UT覆盖率的需求

如之前所说，这样的情况下我们的单元测试也能够达到100%的覆盖率。这听起来很不错。但是，这样的单元测试的内核里有着其先天的不足。

### 依赖被测对象实现细节
可以这么说，白盒的单元测试代码的输入是已经实现的功能代码。这样的代码会在执行过程中逐步校验被测类在某个场景下会执行的具体步骤。

因此每每修改一个类的具体实现，我们的程序员都不得不花精力去“适配”单元测试的代码。若如此做，我们的单元测试用例将不能做到对被测类任何修改及重构的开放性。这种情况下某个类做了重构，其单元测试用例代码都不得不做大规模的重写。

### 不能保证被测对象功能正确
由于UT代码是完全参考被测类的代码来写的。因此该类的单元测试用例需要覆盖哪几个场景，每个场景下类的行为是怎样的都完全取决与被测类的实现。可以说，单元测试用例代码在这中情况下只是产品功能代码的另一种表现形式（部分表现形式）。因此单元测试代码并没有相比我们的被测类代码提供更多的信息。

有一个问题是，如果被测类的实现存在问题（例如没有考虑到某个异常场景），基于该代码产生的单元测试用例同样不能覆盖到这个异常。因此UT就没有起到任何检验被测类的作用，同样的就不能保证被测类的功能正确。

## 黑盒测试
毋庸置疑，把被测类当作一个黑盒来写单元测试的难度比之前那一种要难许多。但是这样的难度换来的好处同样非常多。这样的单元测试用例也符合TDD思想的核心。

把被测对象作为黑盒，而先于实现代码输出单元测试用例是可能的。一个典型的例子就是如[leetcode](https://leetcode.com)这样的网络编程挑战平台。平台上有很多的题目，并且它为每一道题目提供了足够的测试用例来判断每个挑战者提交的代码功能是否完整。每个挑战者提交的答案里必定包含多种不同的实现方式，但这并不妨碍平台有一份公共的单元测试用例。

接下来我们讲一讲这种测试的一些优势。
### 依赖被测对象的抽象
交付的单元测试代码如果依赖的是被测类的抽象的话，则表明改单元测试代码的输入不是产品实现代码，而是产品设计。在产品设计阶段，我们会得到类的命名以及其主要的数据(fields)和对外提供的接口(methods)。从这个角度来说，在Design的阶段，我们就已经约定了某个类的对外提供的具体服务，以及该类对外提供的某种功能。

比如一个叫做AttachmentMaker的类，其Design内容为
```
class AttachmentMaker{
    An attachmentMaker builds attachment of NE3S feedback or Oats.
    ---
    + Attachment asFeedbackAttachment(BigInteger successful,...,String messageResult)
    + Attachment asOatsAttachment(List<ManagedObject> logEvents, String neName)

}
```
在Design阶段，我们对于该类的基本期望就已经是明确的，即使我们不知道这个类的内部会如何实现：
1. 给定`successful...messageResult`等入参并调用`asFeedbackAttachment`接口时，AttachmentMaker能够构建正确格式的NE3S feedback
2. 给定一个`Events`的列表和`neName`调用asOatsAttachment接口时，AttachmentMaker能够构建正确格式的Oats xml
3. 异常的case，当输入的`List<ManagedObject> logEvents`是空列表时，调用asOatsAttachment输出的attachment的内容应当如何如何。

可以看到，以上的期望便是以文字描述的单元测试用例，我们完全可以把它翻译成UT cases：
```
  public void should_generateCorrectFeedbackAttachment_when_asFeedbackAttachment()
  public void should_generateCorrectOatsAttachment_when_asOatsAttachment()
  ...
```
在代码实现之前，我们可以根据其Design和行为描述输出单元测试用例--- 这符合TDD的基本思想，即优先输出被测对象的测试用例，来保证和约束
产品代码的合理性。

单元测试代码依赖被测对象的抽象时，是根据代码Design来指导单元测试用例代码。反过来，在单元测试用例的实现阶段，我们可以通过写单元测试用例的
这一过程，反过来推敲该Design的合理性，形成Desgin到UT之间相互验证的闭环。
```
        +------------------->-----------+
        |                               |
    +---+-------+              +--------+----+
    | Design    |              |   UT cases  |
    +-----+-----+              +----+--------+
          |                         |
          +---------<---------------+
```
良好Design的类的单元测试应该是简单易实现的。易实现的UT代码表明了对于该被测类的设计职责明确，行为清晰可见。如果程序员在UT阶段发现
实现该类的UT需要大量的tricks，那么表明该类的实现违背了一定的设计原则。这就是UT反过来引导Design方面的改进。

### 能保证被测对象功能正确
我们知道，将被测类作为一个黑盒的单元测试用例面向的是被测对象的功能，这样带来了这类UT一个关键优势---它能够保证被测对象功能的正确。
能够保证被测类功能正确这一点回到了UT测试的初衷。同时，这类UT还为代码的重构提供了保证。在代码重构阶段，充分的UT能够保证被重构的
类对外的行为功能不变，即内部的修改不会产品的其余部分产生功能性的影响。这控制了代码重构的风险，保证了整个产品的功能不受影响。

## 总结

在编写单元测试的代码的过程中，我们应该更多的关注到被测类的行为功能，以一种审慎的态度来对待被测类的实现代码。
